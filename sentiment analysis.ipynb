{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "from subprocess import call\n",
    "from nltk import FreqDist\n",
    "from nltk.util import ngrams\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import sklearn as sk\n",
    "import pickle\n",
    "import json\n",
    "from collections import Counter\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing movie reviews dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://gist.githubusercontent.com/bastings/d47423301cca214e3930061a5a75e177/raw/5113687382919e22b1f09ce71a8fecd1687a5760/reviews.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"reviews.json\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "  reviews = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexicon based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://gist.githubusercontent.com/bastings/d6f99dcb6c82231b94b013031356ba05/raw/f80a0281eba8621b122012c89c8b5e2200b39fd6/sent_lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "# creating lexicon dictionary with required features\n",
    "lexicon_dict = {}\n",
    "\n",
    "with open(\"sent_lexicon\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "  for i in f:\n",
    "    i_list = i.strip().split()\n",
    "\n",
    "    key = i_list[2].split(\"=\")[1]\n",
    "\n",
    "    if i_list[5].split(\"=\")[1] == \"positive\":\n",
    "      value_1 = 1\n",
    "    elif i_list[5].split(\"=\")[1] == \"negative\":\n",
    "      value_1 = -1\n",
    "    else:\n",
    "      value_1 = 0\n",
    "\n",
    "    MULTIPLIER_WEAK = 0.5\n",
    "    MULTIPLIER_STRONG = 1\n",
    "    value_2 = MULTIPLIER_WEAK * value_1 if i_list[0].split(\"=\")[1] == \"weaksubj\" else MULTIPLIER_STRONG * value_1\n",
    "\n",
    "    lexicon_dict[key] = [value_1, value_2]\n",
    "\n",
    "# function to get binary_scores\n",
    "def get_binary_score(review):\n",
    "  binary_score = 0\n",
    "  doc_length = 0\n",
    "\n",
    "  for sentences in review[\"content\"]:\n",
    "    for word, _ in sentences:\n",
    "      try:\n",
    "        binary_score += lexicon_dict[word][0]\n",
    "        # doc_length += 1\n",
    "      except KeyError:\n",
    "        binary_score += 0\n",
    "      \n",
    "      doc_length += 1\n",
    "      \n",
    "  return [binary_score, doc_length]\n",
    "\n",
    "# function to classify reivew\n",
    "def classify_review(parameters):\n",
    "  score, doc_length = parameters\n",
    "  THRESHOLD = 8\n",
    "\n",
    "  if score > THRESHOLD:\n",
    "    return \"POS\"\n",
    "  else:\n",
    "    return \"NEG\"\n",
    "\n",
    "# calculating accuracy\n",
    "classifications = [classify_review(get_binary_score(review)) for review in reviews]\n",
    "token_results = [1 if classification == reviews[i][\"sentiment\"] else 0 for i, classification in enumerate(classifications)]\n",
    "token_accuracy = token_results.count(1)/len(token_results)\n",
    "print(\"Accuracy: %0.2f\" % token_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69\n"
     ]
    }
   ],
   "source": [
    "# function to get weighted scores\n",
    "def get_weighted_score(review):\n",
    "  weighted_score = 0\n",
    "  doc_length = 0\n",
    "\n",
    "  for sentences in review[\"content\"]:\n",
    "    for word, _ in sentences:\n",
    "      try:\n",
    "        weighted_score += lexicon_dict[word][1]\n",
    "        # doc_length += 1\n",
    "      except KeyError:\n",
    "        weighted_score += 0\n",
    "\n",
    "      doc_length += 1\n",
    "\n",
    "  return [weighted_score, doc_length]\n",
    "\n",
    "# calculating accuracy\n",
    "classifications_weighted = [classify_review(get_weighted_score(review)) for review in reviews]\n",
    "magnitude_results = [1 if classification == reviews[i][\"sentiment\"] else 0 for i, classification in enumerate(classifications_weighted)]\n",
    "magnitude_accuracy = magnitude_results.count(1)/len(magnitude_results)\n",
    "print(\"Accuracy: %0.2f\" % magnitude_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating better threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New accuracy of weighted classification: 0.70\n"
     ]
    }
   ],
   "source": [
    "# new threshold classification\n",
    "def classify_review_better(parameters):\n",
    "  score, doc_length = parameters\n",
    "  THRESHOLD = 1.02 * math.log(doc_length)\n",
    "\n",
    "  if score >= THRESHOLD:\n",
    "    return \"POS\"\n",
    "  else:\n",
    "    return \"NEG\"\n",
    "\n",
    "# calculating new weighted classification accuracy\n",
    "classifications_weighted_new = [classify_review_better(get_weighted_score(review)) for review in reviews]\n",
    "magnitude_results_2 = [1 if classification == reviews[i][\"sentiment\"] else 0 for i, classification in enumerate(classifications_weighted_new)]\n",
    "magnitude_accuracy_2 = magnitude_results_2.count(1)/len(magnitude_results_2)\n",
    "print(\"New accuracy of weighted classification: %0.2f\" % magnitude_accuracy_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating probability features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_count = 0\n",
    "negative_count = 0\n",
    "\n",
    "negative_words = {}\n",
    "positive_words = {}\n",
    "\n",
    "# calculating positive/negative counts of words\n",
    "for review in reviews:\n",
    "  if review[\"sentiment\"] == \"NEG\":\n",
    "    negative_count += 1\n",
    "    for sentences in review[\"content\"]:\n",
    "      for word, _ in sentences:\n",
    "        if word not in negative_words:\n",
    "          negative_words[word.lower()] = 1\n",
    "        else:\n",
    "          negative_words[word.lower()] += 1\n",
    "\n",
    "  elif review[\"sentiment\"] == \"POS\":\n",
    "    positive_count += 1\n",
    "    for sentences in review[\"content\"]:\n",
    "      for word, _ in sentences:\n",
    "        if word not in positive_words:\n",
    "          positive_words[word.lower()] = 1\n",
    "        else:\n",
    "          positive_words[word.lower()] += 1\n",
    "\n",
    "# calculating praobability of positive/negative classes\n",
    "p_positive = positive_count/(positive_count + negative_count)\n",
    "p_negative = negative_count/(positive_count + negative_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy with Naive Bayes: 0.85\n"
     ]
    }
   ],
   "source": [
    "def train_bayes_classifier(train_set):\n",
    "  vocabulary_positive = {}\n",
    "  vocabulary_negative = {}\n",
    "\n",
    "  reviews_count_positive = 0\n",
    "  reviews_count_negative = 0\n",
    "\n",
    "  for review in train_set:\n",
    "    sentiment = review[\"sentiment\"]\n",
    "\n",
    "    # counting positive/negative reviews\n",
    "    if sentiment == \"POS\":\n",
    "      reviews_count_positive += 1\n",
    "    elif sentiment == \"NEG\":\n",
    "      reviews_count_negative += 1\n",
    "    \n",
    "    # feature extraction\n",
    "    for sentences in review[\"content\"]:\n",
    "      for word, _ in sentences:\n",
    "        token = word.lower()\n",
    "\n",
    "        if sentiment == \"POS\":\n",
    "          try:\n",
    "            vocabulary_positive[token] += 1\n",
    "          except KeyError:\n",
    "            vocabulary_positive[token] = 1\n",
    "\n",
    "        elif sentiment == \"NEG\":\n",
    "          try:\n",
    "            vocabulary_negative[token] += 1\n",
    "          except KeyError:\n",
    "            vocabulary_negative[token] = 1\n",
    "\n",
    "  # total reviews count\n",
    "  reviews_count_total = len(train_set)\n",
    "\n",
    "  # calculating prior\n",
    "  prior_positive = reviews_count_positive / reviews_count_total\n",
    "  prior_negative = reviews_count_negative / reviews_count_total\n",
    "\n",
    "  # calculating conditional probability\n",
    "  denominator_positive = sum(vocabulary_positive.values())\n",
    "  denominator_negative = sum(vocabulary_negative.values())\n",
    "\n",
    "  conditional_positive = {word: (count/denominator_positive) for word, count in vocabulary_positive.items()}\n",
    "  conditional_negative = {word: (count/denominator_negative) for word, count in vocabulary_negative.items()}\n",
    "\n",
    "  return prior_positive, prior_negative, conditional_positive, conditional_negative\n",
    "\n",
    "\n",
    "def apply_bayes_classifier(review, prior_positive, prior_negative, conditional_positive, conditional_negative):\n",
    "  # vocabulary of positive/negative reviews\n",
    "  positive_words = conditional_positive.keys()\n",
    "  negative_words = conditional_negative.keys()\n",
    "  \n",
    "  # calculating positive/negative scores\n",
    "  score_positive = math.log(prior_positive)\n",
    "  score_negative = math.log(prior_negative)\n",
    "\n",
    "  for sentences in review[\"content\"]:\n",
    "    for word, _ in sentences:\n",
    "      token = word.lower()\n",
    "    \n",
    "      if word in positive_words and word in negative_words:\n",
    "        score_positive += math.log(conditional_positive.get(word, 1))\n",
    "        score_negative += math.log(conditional_negative.get(word, 1))\n",
    "\n",
    "  # classifying review\n",
    "  if score_positive > score_negative:\n",
    "    return \"POS\"\n",
    "  else:\n",
    "    return \"NEG\"\n",
    "\n",
    "# train/test split\n",
    "train_set = [review for review in reviews if (review[\"cv\"] >= 000 and review[\"cv\"] <= 899)]\n",
    "test_set = [review for review in reviews if (review[\"cv\"] >= 900 and review[\"cv\"] <= 999)]\n",
    "\n",
    "# training model\n",
    "prior_positive, prior_negative, conditional_positive, conditional_negative = train_bayes_classifier(train_set)\n",
    "\n",
    "# predicting sentiment\n",
    "predictions = []\n",
    "\n",
    "for review in test_set:\n",
    "  prediction = apply_bayes_classifier(review, prior_positive, prior_negative, conditional_positive, conditional_negative)\n",
    "  \n",
    "  if prediction == review[\"sentiment\"]:\n",
    "    predictions.append(1)\n",
    "  else:\n",
    "    predictions.append(0)\n",
    "\n",
    "# calculating accuracy\n",
    "accuracy = predictions.count(1) / len(predictions)\n",
    "print(f\"Classification accuracy with Naive Bayes: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
