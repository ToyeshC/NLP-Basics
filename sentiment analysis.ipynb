{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "from subprocess import call\n",
    "from nltk import FreqDist\n",
    "from nltk.util import ngrams\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import sklearn as sk\n",
    "import pickle\n",
    "import json\n",
    "from collections import Counter\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing movie reviews dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://gist.githubusercontent.com/bastings/d47423301cca214e3930061a5a75e177/raw/5113687382919e22b1f09ce71a8fecd1687a5760/reviews.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"reviews.json\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "  reviews = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexicon based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://gist.githubusercontent.com/bastings/d6f99dcb6c82231b94b013031356ba05/raw/f80a0281eba8621b122012c89c8b5e2200b39fd6/sent_lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "# creating lexicon dictionary with required features\n",
    "lexicon_dict = {}\n",
    "\n",
    "with open(\"sent_lexicon\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "  for i in f:\n",
    "    i_list = i.strip().split()\n",
    "\n",
    "    key = i_list[2].split(\"=\")[1]\n",
    "\n",
    "    if i_list[5].split(\"=\")[1] == \"positive\":\n",
    "      value_1 = 1\n",
    "    elif i_list[5].split(\"=\")[1] == \"negative\":\n",
    "      value_1 = -1\n",
    "    else:\n",
    "      value_1 = 0\n",
    "\n",
    "    MULTIPLIER_WEAK = 0.5\n",
    "    MULTIPLIER_STRONG = 1\n",
    "    value_2 = MULTIPLIER_WEAK * value_1 if i_list[0].split(\"=\")[1] == \"weaksubj\" else MULTIPLIER_STRONG * value_1\n",
    "\n",
    "    lexicon_dict[key] = [value_1, value_2]\n",
    "\n",
    "# function to get binary_scores\n",
    "def get_binary_score(review):\n",
    "  binary_score = 0\n",
    "  doc_length = 0\n",
    "\n",
    "  for sentences in review[\"content\"]:\n",
    "    for word, _ in sentences:\n",
    "      try:\n",
    "        binary_score += lexicon_dict[word][0]\n",
    "        # doc_length += 1\n",
    "      except KeyError:\n",
    "        binary_score += 0\n",
    "      \n",
    "      doc_length += 1\n",
    "      \n",
    "  return [binary_score, doc_length]\n",
    "\n",
    "# function to classify reivew\n",
    "def classify_review(parameters):\n",
    "  score, doc_length = parameters\n",
    "  THRESHOLD = 8\n",
    "\n",
    "  if score > THRESHOLD:\n",
    "    return \"POS\"\n",
    "  else:\n",
    "    return \"NEG\"\n",
    "\n",
    "# calculating accuracy\n",
    "classifications = [classify_review(get_binary_score(review)) for review in reviews]\n",
    "token_results = [1 if classification == reviews[i][\"sentiment\"] else 0 for i, classification in enumerate(classifications)]\n",
    "token_accuracy = token_results.count(1)/len(token_results)\n",
    "print(\"Accuracy: %0.2f\" % token_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69\n"
     ]
    }
   ],
   "source": [
    "# function to get weighted scores\n",
    "def get_weighted_score(review):\n",
    "  weighted_score = 0\n",
    "  doc_length = 0\n",
    "\n",
    "  for sentences in review[\"content\"]:\n",
    "    for word, _ in sentences:\n",
    "      try:\n",
    "        weighted_score += lexicon_dict[word][1]\n",
    "        # doc_length += 1\n",
    "      except KeyError:\n",
    "        weighted_score += 0\n",
    "\n",
    "      doc_length += 1\n",
    "\n",
    "  return [weighted_score, doc_length]\n",
    "\n",
    "# calculating accuracy\n",
    "classifications_weighted = [classify_review(get_weighted_score(review)) for review in reviews]\n",
    "magnitude_results = [1 if classification == reviews[i][\"sentiment\"] else 0 for i, classification in enumerate(classifications_weighted)]\n",
    "magnitude_accuracy = magnitude_results.count(1)/len(magnitude_results)\n",
    "print(\"Accuracy: %0.2f\" % magnitude_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating better threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New accuracy of weighted classification: 0.70\n"
     ]
    }
   ],
   "source": [
    "# new threshold classification\n",
    "def classify_review_better(parameters):\n",
    "  score, doc_length = parameters\n",
    "  THRESHOLD = 1.02 * math.log(doc_length)\n",
    "\n",
    "  if score >= THRESHOLD:\n",
    "    return \"POS\"\n",
    "  else:\n",
    "    return \"NEG\"\n",
    "\n",
    "# calculating new weighted classification accuracy\n",
    "classifications_weighted_new = [classify_review_better(get_weighted_score(review)) for review in reviews]\n",
    "magnitude_results_2 = [1 if classification == reviews[i][\"sentiment\"] else 0 for i, classification in enumerate(classifications_weighted_new)]\n",
    "magnitude_accuracy_2 = magnitude_results_2.count(1)/len(magnitude_results_2)\n",
    "print(\"New accuracy of weighted classification: %0.2f\" % magnitude_accuracy_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bayes_classifier(train_set, kappa=0):\n",
    "  vocabulary_positive = {}\n",
    "  vocabulary_negative = {}\n",
    "  vocabulary = []\n",
    "\n",
    "  reviews_count_positive = 0\n",
    "  reviews_count_negative = 0\n",
    "\n",
    "  for review in train_set:\n",
    "    sentiment = review[\"sentiment\"]\n",
    "\n",
    "    # counting positive/negative reviews\n",
    "    if sentiment == \"POS\":\n",
    "      reviews_count_positive += 1\n",
    "    elif sentiment == \"NEG\":\n",
    "      reviews_count_negative += 1\n",
    "    \n",
    "    # feature extraction\n",
    "    for sentences in review[\"content\"]:\n",
    "      for word, _ in sentences:\n",
    "        token = word.lower()\n",
    "        vocabulary.append(token)\n",
    "\n",
    "        if sentiment == \"POS\":\n",
    "          try:\n",
    "            vocabulary_positive[token] += 1\n",
    "          except KeyError:\n",
    "            vocabulary_positive[token] = 1\n",
    "\n",
    "        elif sentiment == \"NEG\":\n",
    "          try:\n",
    "            vocabulary_negative[token] += 1\n",
    "          except KeyError:\n",
    "            vocabulary_negative[token] = 1\n",
    "\n",
    "  # vocabulary of training set\n",
    "  vocabulary = list(set(vocabulary))\n",
    "\n",
    "  # total reviews count\n",
    "  reviews_count_total = len(train_set)\n",
    "\n",
    "  # calculating prior\n",
    "  prior_positive = reviews_count_positive / reviews_count_total\n",
    "  prior_negative = reviews_count_negative / reviews_count_total\n",
    "\n",
    "  # calculating conditional probability\n",
    "  denominator_positive = sum(vocabulary_positive.values()) + (len(vocabulary) * kappa)\n",
    "  denominator_negative = sum(vocabulary_negative.values()) + (len(vocabulary) * kappa)\n",
    "\n",
    "  if kappa == 0:\n",
    "    conditional_positive = {word.lower(): (count / denominator_positive) for word, count in vocabulary_positive.items()}\n",
    "    conditional_negative = {word.lower(): (count / denominator_negative) for word, count in vocabulary_negative.items()}\n",
    "    \n",
    "  else:\n",
    "    conditional_positive = {word.lower(): ((count + kappa) / denominator_positive) for word, count in vocabulary_positive.items()}\n",
    "    conditional_negative = {word.lower(): ((count + kappa) / denominator_negative) for word, count in vocabulary_negative.items()}\n",
    "\n",
    "  return vocabulary, prior_positive, prior_negative, conditional_positive, conditional_negative\n",
    "\n",
    "\n",
    "def apply_bayes_classifier(review, voacabulary, prior_positive, prior_negative, conditional_positive, conditional_negative):\n",
    "  # extracting tokens\n",
    "  tokens = []\n",
    "\n",
    "  for sentences in review[\"content\"]:\n",
    "    for word, _ in sentences:\n",
    "      tokens.append(word.lower())\n",
    "\n",
    "  positive_words = conditional_positive.keys()\n",
    "  negative_words = conditional_negative.keys()\n",
    "\n",
    "  tokens_intersection = set(vocabulary).intersection(tokens, positive_words, negative_words)\n",
    "\n",
    "  # calculating scores\n",
    "  score_positive = math.log(prior_positive)\n",
    "  score_negative = math.log(prior_negative)\n",
    "\n",
    "  for token in tokens_intersection:\n",
    "      score_positive += math.log(conditional_positive[token])\n",
    "      score_negative += math.log(conditional_negative[token])\n",
    "\n",
    "  # classifying review\n",
    "  if score_positive > score_negative:\n",
    "    return \"POS\"\n",
    "  else:\n",
    "    return \"NEG\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training / prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy with Naive Bayes: 0.88\n"
     ]
    }
   ],
   "source": [
    "# train/test split\n",
    "train_set = [review for review in reviews if (review[\"cv\"] >= 000 and review[\"cv\"] <= 899)]\n",
    "test_set = [review for review in reviews if (review[\"cv\"] >= 900 and review[\"cv\"] <= 999)]\n",
    "\n",
    "# training model\n",
    "KAPPA = 2\n",
    "vocabulary, prior_positive, prior_negative, conditional_positive, conditional_negative = train_bayes_classifier(train_set, KAPPA)\n",
    "\n",
    "# predicting sentiment\n",
    "predictions = []\n",
    "\n",
    "for review in test_set:\n",
    "  prediction = apply_bayes_classifier(review, vocabulary, prior_positive, prior_negative, conditional_positive, conditional_negative)\n",
    "  \n",
    "  if prediction == review[\"sentiment\"]:\n",
    "    predictions.append(1)\n",
    "  else:\n",
    "    predictions.append(0)\n",
    "\n",
    "# calculating accuracy\n",
    "accuracy = predictions.count(1) / len(predictions)\n",
    "print(f\"Classification accuracy with Naive Bayes: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
