{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "from subprocess import call\n",
    "from nltk import FreqDist\n",
    "from nltk.util import ngrams\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import sklearn as sk\n",
    "import pickle\n",
    "import json\n",
    "from collections import Counter\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing movie reviews dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://gist.githubusercontent.com/bastings/d47423301cca214e3930061a5a75e177/raw/5113687382919e22b1f09ce71a8fecd1687a5760/reviews.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"reviews.json\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "  reviews = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexicon based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://gist.githubusercontent.com/bastings/d6f99dcb6c82231b94b013031356ba05/raw/f80a0281eba8621b122012c89c8b5e2200b39fd6/sent_lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "# creating lexicon dictionary with required features\n",
    "lexicon_dict = {}\n",
    "\n",
    "with open(\"sent_lexicon\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "  for i in f:\n",
    "    i_list = i.strip().split()\n",
    "\n",
    "    key = i_list[2].split(\"=\")[1]\n",
    "\n",
    "    if i_list[5].split(\"=\")[1] == \"positive\":\n",
    "      value_1 = 1\n",
    "    elif i_list[5].split(\"=\")[1] == \"negative\":\n",
    "      value_1 = -1\n",
    "    else:\n",
    "      value_1 = 0\n",
    "\n",
    "    MULTIPLIER_WEAK = 0.5\n",
    "    MULTIPLIER_STRONG = 1\n",
    "    value_2 = MULTIPLIER_WEAK * value_1 if i_list[0].split(\"=\")[1] == \"weaksubj\" else MULTIPLIER_STRONG * value_1\n",
    "\n",
    "    lexicon_dict[key] = [value_1, value_2]\n",
    "\n",
    "# function to get binary_scores\n",
    "def get_binary_score(review):\n",
    "  binary_score = 0\n",
    "  doc_length = 0\n",
    "\n",
    "  for sentences in review[\"content\"]:\n",
    "    for word, _ in sentences:\n",
    "      try:\n",
    "        binary_score += lexicon_dict[word][0]\n",
    "        # doc_length += 1\n",
    "      except KeyError:\n",
    "        binary_score += 0\n",
    "      \n",
    "      doc_length += 1\n",
    "      \n",
    "  return [binary_score, doc_length]\n",
    "\n",
    "# function to classify reivew\n",
    "def classify_review(parameters):\n",
    "  score, doc_length = parameters\n",
    "  THRESHOLD = 8\n",
    "\n",
    "  if score > THRESHOLD:\n",
    "    return \"POS\"\n",
    "  else:\n",
    "    return \"NEG\"\n",
    "\n",
    "# calculating accuracy\n",
    "classifications = [classify_review(get_binary_score(review)) for review in reviews]\n",
    "token_results = [1 if classification == reviews[i][\"sentiment\"] else 0 for i, classification in enumerate(classifications)]\n",
    "token_accuracy = token_results.count(1)/len(token_results)\n",
    "print(\"Accuracy: %0.2f\" % token_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69\n"
     ]
    }
   ],
   "source": [
    "# function to get weighted scores\n",
    "def get_weighted_score(review):\n",
    "  weighted_score = 0\n",
    "  doc_length = 0\n",
    "\n",
    "  for sentences in review[\"content\"]:\n",
    "    for word, _ in sentences:\n",
    "      try:\n",
    "        weighted_score += lexicon_dict[word][1]\n",
    "        # doc_length += 1\n",
    "      except KeyError:\n",
    "        weighted_score += 0\n",
    "\n",
    "      doc_length += 1\n",
    "\n",
    "  return [weighted_score, doc_length]\n",
    "\n",
    "# calculating accuracy\n",
    "classifications_weighted = [classify_review(get_weighted_score(review)) for review in reviews]\n",
    "magnitude_results = [1 if classification == reviews[i][\"sentiment\"] else 0 for i, classification in enumerate(classifications_weighted)]\n",
    "magnitude_accuracy = magnitude_results.count(1)/len(magnitude_results)\n",
    "print(\"Accuracy: %0.2f\" % magnitude_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating better threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New accuracy of weighted classification: 0.70\n"
     ]
    }
   ],
   "source": [
    "# new threshold classification\n",
    "def classify_review_better(parameters):\n",
    "  score, doc_length = parameters\n",
    "  THRESHOLD = 1.02 * math.log(doc_length)\n",
    "\n",
    "  if score >= THRESHOLD:\n",
    "    return \"POS\"\n",
    "  else:\n",
    "    return \"NEG\"\n",
    "\n",
    "# calculating new weighted classification accuracy\n",
    "classifications_weighted_new = [classify_review_better(get_weighted_score(review)) for review in reviews]\n",
    "magnitude_results_2 = [1 if classification == reviews[i][\"sentiment\"] else 0 for i, classification in enumerate(classifications_weighted_new)]\n",
    "magnitude_accuracy_2 = magnitude_results_2.count(1)/len(magnitude_results_2)\n",
    "print(\"New accuracy of weighted classification: %0.2f\" % magnitude_accuracy_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
