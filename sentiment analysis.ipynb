{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "from subprocess import call\n",
    "from nltk import FreqDist\n",
    "from nltk.util import ngrams\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import sklearn as sk\n",
    "import pickle\n",
    "import json\n",
    "from collections import Counter\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing movie reviews dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://gist.githubusercontent.com/bastings/d47423301cca214e3930061a5a75e177/raw/5113687382919e22b1f09ce71a8fecd1687a5760/reviews.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"reviews.json\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "  reviews = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexicon based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://gist.githubusercontent.com/bastings/d6f99dcb6c82231b94b013031356ba05/raw/f80a0281eba8621b122012c89c8b5e2200b39fd6/sent_lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "# creating lexicon dictionary with required features\n",
    "lexicon_dict = {}\n",
    "\n",
    "with open(\"sent_lexicon\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "  for i in f:\n",
    "    i_list = i.strip().split()\n",
    "\n",
    "    key = i_list[2].split(\"=\")[1]\n",
    "\n",
    "    if i_list[5].split(\"=\")[1] == \"positive\":\n",
    "      value_1 = 1\n",
    "    elif i_list[5].split(\"=\")[1] == \"negative\":\n",
    "      value_1 = -1\n",
    "    else:\n",
    "      value_1 = 0\n",
    "\n",
    "    MULTIPLIER_WEAK = 0.5\n",
    "    MULTIPLIER_STRONG = 1\n",
    "    value_2 = MULTIPLIER_WEAK * value_1 if i_list[0].split(\"=\")[1] == \"weaksubj\" else MULTIPLIER_STRONG * value_1\n",
    "\n",
    "    lexicon_dict[key] = [value_1, value_2]\n",
    "\n",
    "# function to get binary_scores\n",
    "def get_binary_score(review):\n",
    "  binary_score = 0\n",
    "  doc_length = 0\n",
    "\n",
    "  for sentences in review[\"content\"]:\n",
    "    for word, _ in sentences:\n",
    "      try:\n",
    "        binary_score += lexicon_dict[word][0]\n",
    "        # doc_length += 1\n",
    "      except KeyError:\n",
    "        binary_score += 0\n",
    "      \n",
    "      doc_length += 1\n",
    "      \n",
    "  return [binary_score, doc_length]\n",
    "\n",
    "# function to classify reivew\n",
    "def classify_review(parameters):\n",
    "  score, doc_length = parameters\n",
    "  THRESHOLD = 8\n",
    "\n",
    "  if score > THRESHOLD:\n",
    "    return \"POS\"\n",
    "  else:\n",
    "    return \"NEG\"\n",
    "\n",
    "# calculating accuracy\n",
    "classifications = [classify_review(get_binary_score(review)) for review in reviews]\n",
    "token_results = [1 if classification == reviews[i][\"sentiment\"] else 0 for i, classification in enumerate(classifications)]\n",
    "token_accuracy = token_results.count(1)/len(token_results)\n",
    "print(\"Accuracy: %0.2f\" % token_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69\n"
     ]
    }
   ],
   "source": [
    "# function to get weighted scores\n",
    "def get_weighted_score(review):\n",
    "  weighted_score = 0\n",
    "  doc_length = 0\n",
    "\n",
    "  for sentences in review[\"content\"]:\n",
    "    for word, _ in sentences:\n",
    "      try:\n",
    "        weighted_score += lexicon_dict[word][1]\n",
    "        # doc_length += 1\n",
    "      except KeyError:\n",
    "        weighted_score += 0\n",
    "\n",
    "      doc_length += 1\n",
    "\n",
    "  return [weighted_score, doc_length]\n",
    "\n",
    "# calculating accuracy\n",
    "classifications_weighted = [classify_review(get_weighted_score(review)) for review in reviews]\n",
    "magnitude_results = [1 if classification == reviews[i][\"sentiment\"] else 0 for i, classification in enumerate(classifications_weighted)]\n",
    "magnitude_accuracy = magnitude_results.count(1)/len(magnitude_results)\n",
    "print(\"Accuracy: %0.2f\" % magnitude_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating better threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New accuracy of weighted classification: 0.70\n"
     ]
    }
   ],
   "source": [
    "# new threshold classification\n",
    "def classify_review_better(parameters):\n",
    "  score, doc_length = parameters\n",
    "  THRESHOLD = 1.02 * math.log(doc_length)\n",
    "\n",
    "  if score >= THRESHOLD:\n",
    "    return \"POS\"\n",
    "  else:\n",
    "    return \"NEG\"\n",
    "\n",
    "# calculating new weighted classification accuracy\n",
    "classifications_weighted_new = [classify_review_better(get_weighted_score(review)) for review in reviews]\n",
    "magnitude_results_2 = [1 if classification == reviews[i][\"sentiment\"] else 0 for i, classification in enumerate(classifications_weighted_new)]\n",
    "magnitude_accuracy_2 = magnitude_results_2.count(1)/len(magnitude_results_2)\n",
    "print(\"New accuracy of weighted classification: %0.2f\" % magnitude_accuracy_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class NaiveBayes:\n",
    "  # constructor\n",
    "  def __init__(self, train_set, test_set, kappa=0, stemmer=False, bigram=False, trigram=False):\n",
    "    self.train_set = train_set\n",
    "    self.test_set = test_set\n",
    "    self.kappa = kappa\n",
    "    self.stemmer = stemmer\n",
    "    self.bigram = bigram\n",
    "    self.trigram = trigram\n",
    "\n",
    "    # initialising empty conditional probability dictionaries\n",
    "    self.conditional_bigram_positive = {}\n",
    "    self.conditional_bigram_negative = {}\n",
    "\n",
    "    self.conditional_trigram_positive = {}\n",
    "    self.conditional_trigram_negative = {}\n",
    "\n",
    "    # initialising empty vocabulary for applying classifier\n",
    "    self.tokens_bigram = []\n",
    "    self.tokens_trigram = []\n",
    "\n",
    "    # initialising empty variable to count correct classifications\n",
    "    self.correct_count = []\n",
    "\n",
    "\n",
    "  # count reviews in class\n",
    "  def count_reviews(self):\n",
    "    review_count_positive = 0\n",
    "    review_count_negative = 0\n",
    "\n",
    "    for review in self.train_set:\n",
    "      sentiment = review[\"sentiment\"]\n",
    "\n",
    "      if sentiment == \"POS\":\n",
    "        review_count_positive += 1\n",
    "\n",
    "      elif sentiment == \"NEG\":\n",
    "        review_count_negative += 1\n",
    "\n",
    "    return review_count_positive, review_count_negative\n",
    "\n",
    "\n",
    "  # tokenisation\n",
    "  def tokenise(self, word):\n",
    "    if self.stemmer == False:\n",
    "      return word.lower()\n",
    "    else:\n",
    "      return PorterStemmer().stem(word)\n",
    "\n",
    "\n",
    "  # getting ngram features\n",
    "  def get_ngram_features(self, n):\n",
    "    vocabulary_positive = defaultdict(int)\n",
    "    vocabulary_negative = defaultdict(int)\n",
    "\n",
    "    for review in self.train_set:\n",
    "      sentiment = review[\"sentiment\"]\n",
    "\n",
    "      for sentence in review[\"content\"]:\n",
    "        sentence_ngram = list(ngrams(sentence, n))\n",
    "\n",
    "        for ngram in sentence_ngram:\n",
    "          tokens = tuple(self.tokenise(word[0]) for word in ngram)\n",
    "\n",
    "          if sentiment == \"POS\":\n",
    "            vocabulary_positive[tokens] += 1\n",
    "          elif sentiment == \"NEG\":\n",
    "            vocabulary_negative[tokens] += 1\n",
    "\n",
    "    return vocabulary_positive, vocabulary_negative\n",
    "\n",
    "\n",
    "  # calculating condtional probabilities\n",
    "  def calculate_conditional(self, vocabulary, vocabulary_count):\n",
    "    denominator = sum(vocabulary.values()) + (vocabulary_count * self.kappa)\n",
    "    conditional_vocabulary = {word: ((count + self.kappa) / denominator) for word, count in vocabulary.items()}\n",
    "\n",
    "    return conditional_vocabulary\n",
    "\n",
    "\n",
    "  # training bayes classifier\n",
    "  def train_bayes_classifier(self):\n",
    "    # review count per class\n",
    "    review_count_positive, review_count_negative = self.count_reviews()\n",
    "\n",
    "    # unigram feature extraction\n",
    "    vocabulary_unigram_positive, vocabulary_unigram_negative = self.get_ngram_features(1)\n",
    "\n",
    "    unigram_positive_count = len(set(vocabulary_unigram_positive))\n",
    "    unigram_negative_count = len(set(vocabulary_unigram_negative))\n",
    "\n",
    "    self.conditional_unigram_positive = self.calculate_conditional(vocabulary_unigram_positive, unigram_positive_count)\n",
    "    self.conditional_unigram_negative = self.calculate_conditional(vocabulary_unigram_negative, unigram_negative_count)\n",
    "\n",
    "    # bigram feature extraction\n",
    "    if self.bigram != False:\n",
    "      vocabulary_bigram_positive, vocabulary_bigram_negative = self.get_ngram_features(2)\n",
    "\n",
    "      bigram_positive_count = len(set(vocabulary_bigram_positive))\n",
    "      bigram_negative_count = len(set(vocabulary_bigram_negative))\n",
    "\n",
    "      self.conditional_bigram_positive = self.calculate_conditional(vocabulary_bigram_positive, bigram_positive_count)\n",
    "      self.conditional_bigram_negative = self.calculate_conditional(vocabulary_bigram_negative, bigram_negative_count)\n",
    "\n",
    "    # trigram feature extraction\n",
    "    if self.trigram != False:\n",
    "      vocabulary_trigram_positive, vocabulary_trigram_negative = self.get_ngram_features(3)\n",
    "\n",
    "      trigram_positive_count = len(set(vocabulary_trigram_positive))\n",
    "      trigram_negative_count = len(set(vocabulary_trigram_negative))\n",
    "\n",
    "      self.conditional_trigram_positive = self.calculate_conditional(vocabulary_trigram_positive, trigram_positive_count)\n",
    "      self.conditional_trigram_negative = self.calculate_conditional(vocabulary_trigram_negative, trigram_negative_count)\n",
    "\n",
    "    # conditional probability dictionary\n",
    "    self.conditional_positive = self.conditional_unigram_positive | self.conditional_bigram_positive | self.conditional_trigram_positive\n",
    "    self.conditional_negative = self.conditional_unigram_negative | self.conditional_bigram_negative | self.conditional_trigram_negative\n",
    "\n",
    "    # total number of reviews\n",
    "    reviews_count = len(self.train_set)\n",
    "\n",
    "    # calculating prior\n",
    "    self.prior_positive = review_count_positive / reviews_count\n",
    "    self.prior_negative = review_count_negative / reviews_count\n",
    "\n",
    "\n",
    "  # extract tokens from review\n",
    "  def extract_tokens(self, review, n):\n",
    "    tokens = []\n",
    "\n",
    "    for sentence in review[\"content\"]:\n",
    "        sentence_ngram = list(ngrams(sentence, n))\n",
    "\n",
    "        for ngram in sentence_ngram:\n",
    "            tokens.append(tuple(self.tokenise(word[0]) for word in ngram))\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "  # calculating score\n",
    "  def calculate_score(self, tokens_intersection):\n",
    "    score_positive = math.log(self.prior_positive)\n",
    "    score_negative = math.log(self.prior_negative)\n",
    "\n",
    "    for token in tokens_intersection:\n",
    "        score_positive += math.log(self.conditional_positive[token])\n",
    "        score_negative += math.log(self.conditional_negative[token])\n",
    "\n",
    "    return score_positive, score_negative\n",
    "\n",
    "\n",
    "  # applying bayes theorem\n",
    "  def apply_bayes(self):\n",
    "    for review in self.test_set:\n",
    "      # extracting tokens\n",
    "      self.tokens_unigram = self.extract_tokens(review, 1)\n",
    "\n",
    "      if self.bigram != False:\n",
    "        self.tokens_bigram = self.extract_tokens(review, 2)\n",
    "\n",
    "      if self.trigram != False:\n",
    "        self.tokens_trigram = self.extract_tokens(review, 3)\n",
    "      \n",
    "      tokens = self.tokens_unigram + self.tokens_bigram + self.tokens_trigram\n",
    "\n",
    "      # removing unseen words\n",
    "      positive_words = self.conditional_positive.keys()\n",
    "      negative_words = self.conditional_negative.keys()\n",
    "\n",
    "      tokens_intersection = set(tokens).intersection(positive_words, negative_words)\n",
    "\n",
    "      # calculating scores\n",
    "      score_positive, score_negative = self.calculate_score(tokens_intersection)\n",
    "\n",
    "      # classifying review\n",
    "      sentiment = review[\"sentiment\"]\n",
    "\n",
    "      if score_positive > score_negative:\n",
    "        if sentiment == \"POS\":\n",
    "          self.correct_count.append(1)\n",
    "        else:\n",
    "          self.correct_count.append(0)\n",
    "\n",
    "      else:\n",
    "        if sentiment == \"NEG\":\n",
    "          self.correct_count.append(1)\n",
    "        else:\n",
    "          self.correct_count.append(0)\n",
    "\n",
    "\n",
    "  # calculating accuracy\n",
    "  def classify_and_get_accuracy(self):\n",
    "    self.train_bayes_classifier()\n",
    "    self.apply_bayes()\n",
    "\n",
    "    accuracy = sum(self.correct_count) / len(self.correct_count)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy with Naive Bayes: 86.50%\n"
     ]
    }
   ],
   "source": [
    "# train/test split\n",
    "train_set = [review for review in reviews if (review[\"cv\"] >= 000 and review[\"cv\"] <= 899)]\n",
    "test_set = [review for review in reviews if (review[\"cv\"] >= 900 and review[\"cv\"] <= 999)]\n",
    "\n",
    "# creating classifier\n",
    "classifier = NaiveBayes(train_set, test_set)\n",
    "\n",
    "# calculating accuracy\n",
    "accuracy = classifier.classify_and_get_accuracy()\n",
    "\n",
    "print(f\"Classification accuracy with Naive Bayes: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy with smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy with Naive Bayes: 84.00%\n"
     ]
    }
   ],
   "source": [
    "# train/test split\n",
    "train_set = [review for review in reviews if (review[\"cv\"] >= 000 and review[\"cv\"] <= 899)]\n",
    "test_set = [review for review in reviews if (review[\"cv\"] >= 900 and review[\"cv\"] <= 999)]\n",
    "\n",
    "# setting kappa\n",
    "kappa = 1\n",
    "\n",
    "# creating classifier\n",
    "classifier = NaiveBayes(train_set, test_set, kappa=kappa)\n",
    "\n",
    "# calculating accuracy\n",
    "accuracy = classifier.classify_and_get_accuracy()\n",
    "\n",
    "print(f\"Classification accuracy with Naive Bayes: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round-robin cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting k folds\n",
    "def get_k_folds(k):\n",
    "  dataset = {}\n",
    "\n",
    "  for review in reviews:\n",
    "    try:\n",
    "      dataset[review[\"cv\"] % k].append(review)\n",
    "    except KeyError:\n",
    "      dataset[review[\"cv\"] % k] = []\n",
    "      dataset[review[\"cv\"] % k].append(review)\n",
    "\n",
    "  return dataset\n",
    "\n",
    "\n",
    "# getting round robin accuracy\n",
    "def get_round_robin_accuracies(k_folds, kappa=0, stemmer=False, bigram=False, trigram=False):\n",
    "  accuracies = []\n",
    "\n",
    "  # train / test split\n",
    "  for key_1 in k_folds:\n",
    "    test_set = k_folds[key_1]\n",
    "    train_set = []\n",
    "\n",
    "    for key_2, value in k_folds.items():\n",
    "      if key_1 != key_2:\n",
    "        train_set.extend(value)\n",
    "\n",
    "    # creating classifier\n",
    "    classifier = NaiveBayes(train_set, test_set, kappa, stemmer, bigram, trigram)\n",
    "\n",
    "    # calculating accuracy\n",
    "    accuracy = classifier.classify_and_get_accuracy()\n",
    "\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "  return accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy with smoothing, cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy per fold: 81.50%\n"
     ]
    }
   ],
   "source": [
    "# initialising number of folds\n",
    "k = 10\n",
    "\n",
    "# creating k folds\n",
    "k_folds = get_k_folds(k)\n",
    "\n",
    "# calculating accuracy\n",
    "accuracies = get_round_robin_accuracies(k_folds, kappa)\n",
    "\n",
    "# printing accuracies\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "print(f\"Average accuracy per fold: {average_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy with smoothing, cross-validation, stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy per fold: 81.45%\n"
     ]
    }
   ],
   "source": [
    "# calculating accuracy\n",
    "accuracies = get_round_robin_accuracies(k_folds, kappa, stemmer=True)\n",
    "\n",
    "# printing accuracies\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "print(f\"Average accuracy per fold: {average_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy with smoothing, cross-validation, ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy per fold for unigram + bigram + trigram: 80.75%\n"
     ]
    }
   ],
   "source": [
    "# calculating accuracy\n",
    "accuracies = get_round_robin_accuracies(k_folds, kappa, bigram=True, trigram=True)\n",
    "\n",
    "# printing accuracies\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "print(f\"Average accuracy per fold for unigram + bigram + trigram: {average_accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
