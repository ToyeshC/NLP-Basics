{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "from subprocess import call\n",
    "from nltk import FreqDist\n",
    "from nltk.util import ngrams\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import sklearn as sk\n",
    "import pickle\n",
    "import json\n",
    "from collections import Counter\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing movie reviews dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://gist.githubusercontent.com/bastings/d47423301cca214e3930061a5a75e177/raw/5113687382919e22b1f09ce71a8fecd1687a5760/reviews.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"reviews.json\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "  reviews = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexicon based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://gist.githubusercontent.com/bastings/d6f99dcb6c82231b94b013031356ba05/raw/f80a0281eba8621b122012c89c8b5e2200b39fd6/sent_lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "# creating lexicon dictionary with required features\n",
    "lexicon_dict = {}\n",
    "\n",
    "with open(\"sent_lexicon\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "  for i in f:\n",
    "    i_list = i.strip().split()\n",
    "\n",
    "    key = i_list[2].split(\"=\")[1]\n",
    "\n",
    "    if i_list[5].split(\"=\")[1] == \"positive\":\n",
    "      value_1 = 1\n",
    "    elif i_list[5].split(\"=\")[1] == \"negative\":\n",
    "      value_1 = -1\n",
    "    else:\n",
    "      value_1 = 0\n",
    "\n",
    "    MULTIPLIER_WEAK = 0.5\n",
    "    MULTIPLIER_STRONG = 1\n",
    "    value_2 = MULTIPLIER_WEAK * value_1 if i_list[0].split(\"=\")[1] == \"weaksubj\" else MULTIPLIER_STRONG * value_1\n",
    "\n",
    "    lexicon_dict[key] = [value_1, value_2]\n",
    "\n",
    "# function to get binary_scores\n",
    "def get_binary_score(review):\n",
    "  binary_score = 0\n",
    "  doc_length = 0\n",
    "\n",
    "  for sentences in review[\"content\"]:\n",
    "    for word, _ in sentences:\n",
    "      try:\n",
    "        binary_score += lexicon_dict[word][0]\n",
    "        # doc_length += 1\n",
    "      except KeyError:\n",
    "        binary_score += 0\n",
    "      \n",
    "      doc_length += 1\n",
    "      \n",
    "  return [binary_score, doc_length]\n",
    "\n",
    "# function to classify reivew\n",
    "def classify_review(parameters):\n",
    "  score, doc_length = parameters\n",
    "  THRESHOLD = 8\n",
    "\n",
    "  if score > THRESHOLD:\n",
    "    return \"POS\"\n",
    "  else:\n",
    "    return \"NEG\"\n",
    "\n",
    "# calculating accuracy\n",
    "classifications = [classify_review(get_binary_score(review)) for review in reviews]\n",
    "token_results = [1 if classification == reviews[i][\"sentiment\"] else 0 for i, classification in enumerate(classifications)]\n",
    "token_accuracy = token_results.count(1)/len(token_results)\n",
    "print(\"Accuracy: %0.2f\" % token_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69\n"
     ]
    }
   ],
   "source": [
    "# function to get weighted scores\n",
    "def get_weighted_score(review):\n",
    "  weighted_score = 0\n",
    "  doc_length = 0\n",
    "\n",
    "  for sentences in review[\"content\"]:\n",
    "    for word, _ in sentences:\n",
    "      try:\n",
    "        weighted_score += lexicon_dict[word][1]\n",
    "        # doc_length += 1\n",
    "      except KeyError:\n",
    "        weighted_score += 0\n",
    "\n",
    "      doc_length += 1\n",
    "\n",
    "  return [weighted_score, doc_length]\n",
    "\n",
    "# calculating accuracy\n",
    "classifications_weighted = [classify_review(get_weighted_score(review)) for review in reviews]\n",
    "magnitude_results = [1 if classification == reviews[i][\"sentiment\"] else 0 for i, classification in enumerate(classifications_weighted)]\n",
    "magnitude_accuracy = magnitude_results.count(1)/len(magnitude_results)\n",
    "print(\"Accuracy: %0.2f\" % magnitude_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating better threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New accuracy of weighted classification: 0.70\n"
     ]
    }
   ],
   "source": [
    "# new threshold classification\n",
    "def classify_review_better(parameters):\n",
    "  score, doc_length = parameters\n",
    "  THRESHOLD = 1.02 * math.log(doc_length)\n",
    "\n",
    "  if score >= THRESHOLD:\n",
    "    return \"POS\"\n",
    "  else:\n",
    "    return \"NEG\"\n",
    "\n",
    "# calculating new weighted classification accuracy\n",
    "classifications_weighted_new = [classify_review_better(get_weighted_score(review)) for review in reviews]\n",
    "magnitude_results_2 = [1 if classification == reviews[i][\"sentiment\"] else 0 for i, classification in enumerate(classifications_weighted_new)]\n",
    "magnitude_accuracy_2 = magnitude_results_2.count(1)/len(magnitude_results_2)\n",
    "print(\"New accuracy of weighted classification: %0.2f\" % magnitude_accuracy_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bayes_classifier(train_set, kappa, stemmer):\n",
    "  vocabulary_positive = {}\n",
    "  vocabulary_negative = {}\n",
    "  vocabulary = []\n",
    "\n",
    "  reviews_count_positive = 0\n",
    "  reviews_count_negative = 0\n",
    "\n",
    "  for review in train_set:\n",
    "    sentiment = review[\"sentiment\"]\n",
    "\n",
    "    # counting positive/negative reviews\n",
    "    if sentiment == \"POS\":\n",
    "      reviews_count_positive += 1\n",
    "    elif sentiment == \"NEG\":\n",
    "      reviews_count_negative += 1\n",
    "\n",
    "    # feature extraction\n",
    "    for sentences in review[\"content\"]:\n",
    "      for word, _ in sentences:\n",
    "        if stemmer == False:\n",
    "          token = word.lower()\n",
    "        else:\n",
    "          token = stemmer.stem(word)\n",
    "        vocabulary.append(token)\n",
    "\n",
    "        if sentiment == \"POS\":\n",
    "          try:\n",
    "            vocabulary_positive[token] += 1\n",
    "          except KeyError:\n",
    "            vocabulary_positive[token] = 1\n",
    "\n",
    "        elif sentiment == \"NEG\":\n",
    "          try:\n",
    "            vocabulary_negative[token] += 1\n",
    "          except KeyError:\n",
    "            vocabulary_negative[token] = 1\n",
    "\n",
    "  # vocabulary of training set\n",
    "  vocabulary = set(vocabulary)\n",
    "\n",
    "  # total reviews count\n",
    "  reviews_count_total = len(train_set)\n",
    "\n",
    "  # calculating prior\n",
    "  prior_positive = reviews_count_positive / reviews_count_total\n",
    "  prior_negative = reviews_count_negative / reviews_count_total\n",
    "\n",
    "  # calculating conditional probability\n",
    "  denominator_positive = sum(vocabulary_positive.values()) + (len(vocabulary) * kappa)\n",
    "  denominator_negative = sum(vocabulary_negative.values()) + (len(vocabulary) * kappa)\n",
    "\n",
    "  conditional_positive = {word: ((count + kappa) / denominator_positive) for word, count in vocabulary_positive.items()}\n",
    "  conditional_negative = {word: ((count + kappa) / denominator_negative) for word, count in vocabulary_negative.items()}\n",
    "\n",
    "  return prior_positive, prior_negative, conditional_positive, conditional_negative\n",
    "\n",
    "\n",
    "def apply_bayes_classifier(review, prior_positive, prior_negative, conditional_positive, conditional_negative, stemmer):\n",
    "  # extracting tokens\n",
    "  tokens = []\n",
    "\n",
    "  for sentences in review[\"content\"]:\n",
    "    for word, _ in sentences:\n",
    "      if stemmer == False:\n",
    "        tokens.append(word.lower())\n",
    "      else:\n",
    "        tokens.append(stemmer.stem(word))\n",
    "\n",
    "  positive_words = conditional_positive.keys()\n",
    "  negative_words = conditional_negative.keys()\n",
    "\n",
    "  tokens_intersection = set(tokens).intersection(positive_words, negative_words)\n",
    "\n",
    "  # calculating scores\n",
    "  score_positive = math.log(prior_positive)\n",
    "  score_negative = math.log(prior_negative)\n",
    "\n",
    "  for token in tokens_intersection:\n",
    "      score_positive += math.log(conditional_positive[token])\n",
    "      score_negative += math.log(conditional_negative[token])\n",
    "\n",
    "  # classifying review\n",
    "  if score_positive > score_negative:\n",
    "    return \"POS\"\n",
    "  else:\n",
    "    return \"NEG\"\n",
    "\n",
    "\n",
    "def get_accuracy(train_set, test_set, kappa=0, stemmer=False):\n",
    "  # training model\n",
    "  prior_positive, prior_negative, conditional_positive, conditional_negative = train_bayes_classifier(train_set, kappa, stemmer)\n",
    "\n",
    "  # predicting sentiment\n",
    "  predictions = []\n",
    "\n",
    "  for review in test_set:\n",
    "    prediction = apply_bayes_classifier(review, prior_positive, prior_negative, conditional_positive, conditional_negative, stemmer)\n",
    "\n",
    "    if prediction == review[\"sentiment\"]:\n",
    "      predictions.append(1)\n",
    "    else:\n",
    "      predictions.append(0)\n",
    "\n",
    "  # calculating accuracy\n",
    "  accuracy = predictions.count(1) / len(predictions)\n",
    "\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy without smoothing, cross-validation, stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy with Naive Bayes: 86.50%\n"
     ]
    }
   ],
   "source": [
    "# train/test split\n",
    "train_set = [review for review in reviews if (review[\"cv\"] >= 000 and review[\"cv\"] <= 899)]\n",
    "test_set = [review for review in reviews if (review[\"cv\"] >= 900 and review[\"cv\"] <= 999)]\n",
    "\n",
    "accuracy = get_accuracy(train_set, test_set)\n",
    "print(f\"Classification accuracy with Naive Bayes: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy with smoothing; without cross-validation, stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy with Naive Bayes after smoothing: 87.50%\n"
     ]
    }
   ],
   "source": [
    "# train/test split\n",
    "train_set = [review for review in reviews if (review[\"cv\"] >= 000 and review[\"cv\"] <= 899)]\n",
    "test_set = [review for review in reviews if (review[\"cv\"] >= 900 and review[\"cv\"] <= 999)]\n",
    "\n",
    "KAPPA = 2\n",
    "\n",
    "accuracy = get_accuracy(train_set, test_set, KAPPA)\n",
    "print(f\"Classification accuracy with Naive Bayes after smoothing: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round-robin cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy per fold: 82.35%\n"
     ]
    }
   ],
   "source": [
    "def get_round_robin_accuracy(reviews, N=10, kappa=0, stemmer=False):\n",
    "  # creating k-folds\n",
    "  dataset = {}\n",
    "  accuracies = []\n",
    "\n",
    "  for review in reviews:\n",
    "    try:\n",
    "      dataset[review[\"cv\"] % N].append(review)\n",
    "    except KeyError:\n",
    "      dataset[review[\"cv\"] % N] = []\n",
    "      dataset[review[\"cv\"] % N].append(review)\n",
    "\n",
    "  for key_1 in dataset:\n",
    "    test_set = dataset[key_1]\n",
    "    train_set = []\n",
    "\n",
    "    for key_2, value in dataset.items():\n",
    "      if key_1 != key_2:\n",
    "        train_set.extend(value)\n",
    "\n",
    "    # calculating accuracy\n",
    "    accuracy = get_accuracy(train_set, test_set, kappa, stemmer)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "  return accuracies\n",
    "\n",
    "# hyper-parameters\n",
    "N = 10\n",
    "KAPPA = 1\n",
    "\n",
    "# calculating accuracy\n",
    "accuracies = get_round_robin_accuracy(reviews, N, KAPPA)\n",
    "accuracy = sum(accuracies) / len(accuracies)\n",
    "print(f\"Average accuracy per fold: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy with smoothing, cross-validation, stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy per fold: 82.05%\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameters\n",
    "N = 10\n",
    "KAPPA = 1\n",
    "\n",
    "# initialising porter stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "accuracies = get_round_robin_accuracy(reviews, N, KAPPA, stemmer)\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "print(f\"Average accuracy per fold: {average_accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
